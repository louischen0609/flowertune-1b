# Centralized Training (Centralized Finetuning) 參數設定檔
seed: 42

# model/data params
global_model: 'meta-llama/Llama-3.2-1B'
data_path: 'dolly-dir-20-client-json' # 指定包含多個 JSON 格式資料集的目錄
test_path: './data/global_test.json'
output_dir: './lora-centralized-1B-category-0609' # 此為基礎輸出目錄，腳本會在此目錄下為每個檔案的每個 epoch 創建子目錄
load_in_4bit: true # 設定為 true 以 4-bit 量化載入模型
load_in_8bit: false  # 若 load_in_4bit 為 false，則此設定為 true 時以 8-bit 量化載入模型

# Wandb Configuration
use_wandb: true
wandb_project: "centralized-llm-categoty"
wandb_run_name_prefix: "category"
wandb_entity: null # Optional: Your wandb entity/team name, e.g., "my-team"

# training hyperparams
batch_size: 16
micro_batch_size: 8
num_epochs: 10 # 每個 JSON 資料檔案的訓練 epoch 數
learning_rate: 3.0e-5
val_set_size: 0.1 # 修改此處：使用 10% 資料作為驗證集
cutoff_len: 1024

# LoRA hyperparams
lora_r: 8
lora_alpha: 16
lora_dropout: 0.1
lora_target_modules: [ "q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "down_proj", "up_proj" ]

# llm hyperparams
train_on_inputs: true
group_by_length: false
prompt_template_name: "alpaca" 